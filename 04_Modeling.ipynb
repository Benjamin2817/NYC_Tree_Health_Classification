{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (accuracy_score, classification_report, f1_score, \n",
    "                             precision_score, recall_score)\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import data split and preprocessed in attached notebooks\n",
    "X_train = pd.read_csv('data/X_train.csv')\n",
    "y_train = pd.read_csv('data/y_train.csv')\n",
    "X_test = pd.read_csv('data/X_test.csv')\n",
    "y_test = pd.read_csv('data/y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = SMOTE().fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_retriever(true_results, predictions):\n",
    "    precision = precision_score(true_results, predictions, average='weighted') * 100\n",
    "    recall = recall_score(true_results, predictions, average='weighted') * 100\n",
    "    accuracy = accuracy_score(true_results, predictions) * 100\n",
    "    f1 = f1_score(true_results, predictions, average='weighted') * 100\n",
    "    return precision, recall, accuracy, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm_scores = pd.DataFrame(columns=['Model', 'Precision', 'Recall', 'Accuracy', 'F1_Score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5427860580594885"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_classifier_default_params = DecisionTreeClassifier(random_state=42)\n",
    "dt_classifier_baseline_score = np.mean(cross_val_score(dt_classifier_default_params,\n",
    "                                                       X_train, y_train.values.ravel(), cv=3))\n",
    "dt_classifier_baseline_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Scores\n",
      "Decision Tree Baseline Precision: 70.8802531462495\n",
      "Decision Tree Baseline Recall: 54.29276749707911\n",
      "Decision Tree Baseline Accuracy: 54.29276749707911\n",
      "Decision Tree Baseline F1: 60.6990068570941\n"
     ]
    }
   ],
   "source": [
    "dt_classifier_default_params.fit(X_train, y_train.values.ravel())\n",
    "dt_classifier_baseline_predictions = dt_classifier_default_params.predict(X_test)\n",
    "print('Test Scores')\n",
    "print(f'Decision Tree Baseline Precision: {score_retriever(y_test, dt_classifier_baseline_predictions)[0]}')\n",
    "print(f'Decision Tree Baseline Recall: {score_retriever(y_test, dt_classifier_baseline_predictions)[1]}')\n",
    "print(f'Decision Tree Baseline Accuracy: {score_retriever(y_test, dt_classifier_baseline_predictions)[2]}')\n",
    "print(f'Decision Tree Baseline F1: {score_retriever(y_test, dt_classifier_baseline_predictions)[3]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm_scores = algorithm_scores.append({'Model': 'Decision Tree Baseline',\n",
    "                                            'Precision': score_retriever(y_test, dt_classifier_baseline_predictions)[0],\n",
    "                                            'Recall': score_retriever(y_test, dt_classifier_baseline_predictions)[1],\n",
    "                                            'Accuracy': score_retriever(y_test, dt_classifier_baseline_predictions)[2],\n",
    "                                            'F1_Score': score_retriever(y_test, dt_classifier_baseline_predictions)[3]},\n",
    "                                                        ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.06      0.32      0.10      2232\n",
      "           1       0.19      0.25      0.22      7874\n",
      "           2       0.84      0.61      0.70     42960\n",
      "\n",
      "    accuracy                           0.54     53066\n",
      "   macro avg       0.36      0.39      0.34     53066\n",
      "weighted avg       0.71      0.54      0.61     53066\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, dt_classifier_baseline_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_param_grid = {\n",
    "    'criterion': ['entropy', 'gini'],\n",
    "    'max_depth': [None, 5, 10, 20],\n",
    "    'min_samples_leaf': [1, 5, 10],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_grid_search = GridSearchCV(DecisionTreeClassifier(random_state=42), dt_param_grid, cv=3, n_jobs=-1)\n",
    "dt_grid_search = dt_grid_search.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 5}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_classifier_best_params = DecisionTreeClassifier(criterion=dt_grid_search.best_params_['criterion'],\n",
    "                                                   max_depth=dt_grid_search.best_params_['max_depth'],\n",
    "                                                   min_samples_leaf=dt_grid_search.best_params_['min_samples_leaf'],\n",
    "                                                   min_samples_split=dt_grid_search.best_params_['min_samples_split'],\n",
    "                                                   random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Scores\n",
      "Decision Tree Tuned Precision: 70.87898428160364\n",
      "Decision Tree Tuned Recall: 54.27203859344968\n",
      "Decision Tree Tuned Accuracy: 54.272038593449665\n",
      "Decision Tree Tuned F1: 60.68094725239429\n"
     ]
    }
   ],
   "source": [
    "dt_classifier_best_params.fit(X_train, y_train)\n",
    "dt_best_parameters_predictions = dt_classifier_best_params.predict(X_test)\n",
    "print('Test Scores')\n",
    "print(f'Decision Tree Tuned Precision: {score_retriever(y_test, dt_best_parameters_predictions)[0]}')\n",
    "print(f'Decision Tree Tuned Recall: {score_retriever(y_test, dt_best_parameters_predictions)[1]}')\n",
    "print(f'Decision Tree Tuned Accuracy: {score_retriever(y_test, dt_best_parameters_predictions)[2]}')\n",
    "print(f'Decision Tree Tuned F1: {score_retriever(y_test, dt_best_parameters_predictions)[3]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm_scores = algorithm_scores.append({'Model': 'Decision Tree Tuned',\n",
    "                                            'Precision': score_retriever(y_test, dt_best_parameters_predictions)[0],\n",
    "                                            'Recall': score_retriever(y_test, dt_best_parameters_predictions)[1],\n",
    "                                            'Accuracy': score_retriever(y_test, dt_best_parameters_predictions)[2],\n",
    "                                            'F1_Score': score_retriever(y_test, dt_best_parameters_predictions)[3]},\n",
    "                                                        ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.06      0.32      0.10      2232\n",
      "           1       0.19      0.25      0.21      7874\n",
      "           2       0.84      0.61      0.70     42960\n",
      "\n",
      "    accuracy                           0.54     53066\n",
      "   macro avg       0.36      0.39      0.34     53066\n",
      "weighted avg       0.71      0.54      0.61     53066\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, dt_best_parameters_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5440132139315846"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_classifier_default_params = RandomForestClassifier(random_state=42)\n",
    "rf_classifier_baseline_score = np.mean(cross_val_score(rf_classifier_default_params,\n",
    "                                                       X_train, y_train.values.ravel(), cv=3))\n",
    "rf_classifier_baseline_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Scores\n",
      "Random Forest Baseline Precision: 70.94149156263916\n",
      "Random Forest Baseline Recall: 54.69980778652999\n",
      "Random Forest Baseline Accuracy: 54.69980778652999\n",
      "Random Forest Baseline F1: 61.00714415776275\n"
     ]
    }
   ],
   "source": [
    "rf_classifier_default_params.fit(X_train, y_train.values.ravel())\n",
    "rf_classifier_baseline_predictions = rf_classifier_default_params.predict(X_test)\n",
    "print('Test Scores')\n",
    "print(f'Random Forest Baseline Precision: {score_retriever(y_test, rf_classifier_baseline_predictions)[0]}')\n",
    "print(f'Random Forest Baseline Recall: {score_retriever(y_test, rf_classifier_baseline_predictions)[1]}')\n",
    "print(f'Random Forest Baseline Accuracy: {score_retriever(y_test, rf_classifier_baseline_predictions)[2]}')\n",
    "print(f'Random Forest Baseline F1: {score_retriever(y_test, rf_classifier_baseline_predictions)[3]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm_scores = algorithm_scores.append({'Model': 'Random Forest Baseline',\n",
    "                                            'Precision': score_retriever(y_test, rf_classifier_baseline_predictions)[0],\n",
    "                                            'Recall': score_retriever(y_test, rf_classifier_baseline_predictions)[1],\n",
    "                                            'Accuracy': score_retriever(y_test, rf_classifier_baseline_predictions)[2],\n",
    "                                            'F1_Score': score_retriever(y_test, rf_classifier_baseline_predictions)[3]},\n",
    "                                                        ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.06      0.32      0.10      2232\n",
      "           1       0.20      0.25      0.22      7874\n",
      "           2       0.84      0.61      0.71     42960\n",
      "\n",
      "    accuracy                           0.55     53066\n",
      "   macro avg       0.36      0.39      0.34     53066\n",
      "weighted avg       0.71      0.55      0.61     53066\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, rf_classifier_baseline_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_param_grid = {\n",
    "    'criterion': ['entropy', 'gini'],\n",
    "    'max_depth': [None, 5, 10, 20],\n",
    "    'min_samples_leaf': [1, 5, 10],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'n_estimators': [10, 50, 100]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benja\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "216 fits failed out of a total of 648.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "216 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\benja\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\benja\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 442, in fit\n",
      "    trees = Parallel(\n",
      "  File \"C:\\Users\\benja\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\benja\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\benja\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\benja\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\benja\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\benja\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\benja\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\benja\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 211, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\benja\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\benja\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\benja\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 250, in fit\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\benja\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan 0.54484685 0.54681962 0.54744355\n",
      " 0.54502549 0.54756006 0.54804678        nan        nan        nan\n",
      " 0.51666369 0.52421044 0.52566801 0.51666369 0.52421044 0.52566801\n",
      "        nan        nan        nan 0.49688163 0.50135272 0.50182649\n",
      " 0.49688163 0.50135272 0.50182649        nan        nan        nan\n",
      " 0.41316319 0.41650292 0.41740387 0.41436704 0.41937146 0.41806146\n",
      "        nan        nan        nan 0.41881225 0.41822456 0.41815725\n",
      " 0.41881225 0.41822456 0.41815725        nan        nan        nan\n",
      " 0.4143774  0.42193968 0.42124585 0.4143774  0.42193968 0.42124585\n",
      "        nan        nan        nan 0.45590394 0.46074525 0.46217952\n",
      " 0.45365674 0.45953622 0.4617394         nan        nan        nan\n",
      " 0.45092024 0.45738481 0.45761005 0.45092024 0.45738481 0.45761005\n",
      "        nan        nan        nan 0.45166585 0.4556321  0.45624568\n",
      " 0.45166585 0.4556321  0.45624568        nan        nan        nan\n",
      " 0.52552303 0.53241996 0.53297399 0.52557999 0.53095462 0.53192029\n",
      "        nan        nan        nan 0.50265754 0.50743413 0.50810208\n",
      " 0.50265754 0.50743413 0.50810208        nan        nan        nan\n",
      " 0.48782553 0.49258917 0.49344352 0.48782553 0.49258917 0.49344352\n",
      "        nan        nan        nan 0.54468116 0.54653743 0.54703709\n",
      " 0.54461644 0.54767138 0.54820729        nan        nan        nan\n",
      " 0.51798922 0.52287196 0.52432176 0.51798922 0.52287196 0.52432176\n",
      "        nan        nan        nan 0.49506678 0.50123104 0.50110418\n",
      " 0.49506678 0.50123104 0.50110418        nan        nan        nan\n",
      " 0.41432044 0.42047952 0.42221152 0.4144939  0.42211573 0.42198628\n",
      "        nan        nan        nan 0.41749966 0.41994879 0.42108274\n",
      " 0.41749966 0.41994879 0.42108274        nan        nan        nan\n",
      " 0.41433598 0.42082903 0.42313059 0.41433598 0.42082903 0.42313059\n",
      "        nan        nan        nan 0.4557952  0.46163585 0.46175235\n",
      " 0.45582109 0.46125268 0.4615996         nan        nan        nan\n",
      " 0.45352989 0.45935758 0.45936535 0.45352989 0.45935758 0.45936535\n",
      "        nan        nan        nan 0.45040245 0.45646574 0.45724501\n",
      " 0.45040245 0.45646574 0.45724501        nan        nan        nan\n",
      " 0.5281042  0.5328316  0.5332277  0.52494829 0.53190476 0.5322931\n",
      "        nan        nan        nan 0.50147181 0.50792344 0.50935512\n",
      " 0.50147181 0.50792344 0.50935512        nan        nan        nan\n",
      " 0.48609612 0.49286877 0.49334514 0.48609612 0.49286877 0.49334514]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "rf_grid_search = GridSearchCV(RandomForestClassifier(random_state=42), rf_param_grid, cv=3, n_jobs=-1)\n",
    "rf_grid_search = rf_grid_search.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 10,\n",
       " 'n_estimators': 100}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier_best_params = RandomForestClassifier(criterion=rf_grid_search.best_params_['criterion'],\n",
    "                                                   max_depth=rf_grid_search.best_params_['max_depth'],\n",
    "                                                   min_samples_leaf=rf_grid_search.best_params_['min_samples_leaf'],\n",
    "                                                   min_samples_split=rf_grid_search.best_params_['min_samples_split'],\n",
    "                                                   n_estimators=rf_grid_search.best_params_['n_estimators'],\n",
    "                                                   random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-25-969c89083e59>:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rf_classifier_best_params.fit(X_train, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Scores\n",
      "Random Forest Tuned Precision: 71.34048440544412\n",
      "Random Forest Tuned Recall: 54.125051822259074\n",
      "Random Forest Tuned Accuracy: 54.125051822259074\n",
      "Random Forest Tuned F1: 60.6747613656049\n"
     ]
    }
   ],
   "source": [
    "rf_classifier_best_params.fit(X_train, y_train.values.ravel())\n",
    "rf_best_parameters_predictions = rf_classifier_best_params.predict(X_test)\n",
    "print('Test Scores')\n",
    "print(f'Random Forest Tuned Precision: {score_retriever(y_test, rf_best_parameters_predictions)[0]}')\n",
    "print(f'Random Forest Tuned Recall: {score_retriever(y_test, rf_best_parameters_predictions)[1]}')\n",
    "print(f'Random Forest Tuned Accuracy: {score_retriever(y_test, rf_best_parameters_predictions)[2]}')\n",
    "print(f'Random Forest Tuned F1: {score_retriever(y_test, rf_best_parameters_predictions)[3]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm_scores = algorithm_scores.append({'Model': 'Random Forest Tuned',\n",
    "                                            'Precision': score_retriever(y_test, rf_best_parameters_predictions)[0],\n",
    "                                            'Recall': score_retriever(y_test, rf_best_parameters_predictions)[1],\n",
    "                                            'Accuracy': score_retriever(y_test, rf_best_parameters_predictions)[2],\n",
    "                                            'F1_Score': score_retriever(y_test, rf_best_parameters_predictions)[3]},\n",
    "                                                        ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.06      0.33      0.11      2232\n",
      "           1       0.20      0.26      0.23      7874\n",
      "           2       0.84      0.60      0.70     42960\n",
      "\n",
      "    accuracy                           0.54     53066\n",
      "   macro avg       0.37      0.40      0.35     53066\n",
      "weighted avg       0.71      0.54      0.61     53066\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, rf_best_parameters_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_feature_importance_dict = dict(zip(X_train.columns, rf_classifier_best_params.feature_importances_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummied_categories = ['steward', 'guards', 'borough']\n",
    "for name in dummied_categories:\n",
    "    category_sum = sum([value for key, value in rf_feature_importance_dict.items() if name in key])\n",
    "    remove_keys = [key for key in rf_feature_importance_dict.keys() if name in key]\n",
    "    for key in remove_keys:\n",
    "        rf_feature_importance_dict.pop(key)\n",
    "    rf_feature_importance_dict[name] = category_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "importances = pd.Series(rf_feature_importance_dict.values(), \n",
    "                        index=rf_feature_importance_dict.keys()).sort_values(ascending=False)\n",
    "sns.barplot(x=importances, y=importances.index);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### eXtreme Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07:01:49] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:03:19] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:04:37] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5178571890881507"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_classifier_default_params = XGBClassifier(random_state=42, use_label_encoder=False)\n",
    "xgb_classifier_baseline_score = np.mean(cross_val_score(xgb_classifier_default_params,\n",
    "                                                        X_train, y_train.values.ravel(), cv=3))\n",
    "xgb_classifier_baseline_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07:05:54] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test Scores\n",
      "eXtreme Gradient Boost Baseline Precision: 71.80843557775046\n",
      "eXtreme Gradient Boost Baseline Recall: 61.875777333886106\n",
      "eXtreme Gradient Boost Baseline Accuracy: 61.875777333886106\n",
      "eXtreme Gradient Boost Baseline F1: 66.04130907945893\n"
     ]
    }
   ],
   "source": [
    "xgb_classifier_default_params.fit(X_train, y_train.values.ravel())\n",
    "xgb_classifier_baseline_predictions = xgb_classifier_default_params.predict(X_test)\n",
    "print('Test Scores')\n",
    "print(f'eXtreme Gradient Boost Baseline Precision: {score_retriever(y_test, xgb_classifier_baseline_predictions)[0]}')\n",
    "print(f'eXtreme Gradient Boost Baseline Recall: {score_retriever(y_test, xgb_classifier_baseline_predictions)[1]}')\n",
    "print(f'eXtreme Gradient Boost Baseline Accuracy: {score_retriever(y_test, xgb_classifier_baseline_predictions)[2]}')\n",
    "print(f'eXtreme Gradient Boost Baseline F1: {score_retriever(y_test, xgb_classifier_baseline_predictions)[3]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm_scores = algorithm_scores.append({'Model': 'XGBoost Baseline',\n",
    "                                            'Precision': score_retriever(y_test, xgb_classifier_baseline_predictions)[0],\n",
    "                                            'Recall': score_retriever(y_test, xgb_classifier_baseline_predictions)[1],\n",
    "                                            'Accuracy': score_retriever(y_test, xgb_classifier_baseline_predictions)[2],\n",
    "                                            'F1_Score': score_retriever(y_test, xgb_classifier_baseline_predictions)[3]},\n",
    "                                                        ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.07      0.33      0.12      2232\n",
      "           1       0.23      0.19      0.21      7874\n",
      "           2       0.84      0.71      0.77     42960\n",
      "\n",
      "    accuracy                           0.62     53066\n",
      "   macro avg       0.38      0.41      0.37     53066\n",
      "weighted avg       0.72      0.62      0.66     53066\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, xgb_classifier_baseline_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_param_grid = {\n",
    "    'learning_rate': [0.1, 0.2],\n",
    "    'max_depth': [6],\n",
    "    'min_child_weight': [1, 2],\n",
    "    'n_estimators': [100],\n",
    "    'subsample': [0.5, 0.7]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07:08:03] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:09:53] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:11:25] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:12:55] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:14:38] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:16:01] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:17:25] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:19:12] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:21:03] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:22:56] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:24:24] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:25:51] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:27:22] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:28:53] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:30:31] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:32:09] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:33:39] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:35:06] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:36:30] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:37:59] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:39:31] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:41:02] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:42:29] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:43:48] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[07:45:14] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "xgb_grid_search = GridSearchCV(XGBClassifier(random_state=42, use_label_encoder=False),\n",
    "                               xgb_param_grid, scoring='accuracy', cv=3)\n",
    "xgb_grid_search = xgb_grid_search.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.2,\n",
       " 'max_depth': 6,\n",
       " 'min_child_weight': 2,\n",
       " 'n_estimators': 100,\n",
       " 'subsample': 0.7}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_classifier_best_params = XGBClassifier(learning_rate=xgb_grid_search.best_params_['learning_rate'],\n",
    "                                           max_depth=xgb_grid_search.best_params_['max_depth'],\n",
    "                                           min_child_weight=xgb_grid_search.best_params_['min_child_weight'],\n",
    "                                           n_estimators=xgb_grid_search.best_params_['n_estimators'],\n",
    "                                           subsample=xgb_grid_search.best_params_['subsample'],\n",
    "                                           random_state=42, use_label_encoder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07:47:23] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.2, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=2, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=4, num_parallel_tree=1,\n",
       "              objective='multi:softprob', random_state=42, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=None, subsample=0.7,\n",
       "              tree_method='exact', use_label_encoder=False,\n",
       "              validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_classifier_best_params.fit(X_train, y_train)\n",
    "xgb_best_parameters_predictions = xgb_classifier_best_params.predict(X_test)\n",
    "print('Test Scores')\n",
    "print(f'eXtreme Gradient Boost Tuned Precision: {score_retriever(y_test, xgb_best_parameters_predictions)[0]}')\n",
    "print(f'eXtreme Gradient Boost Tuned Recall: {score_retriever(y_test, xgb_best_parameters_predictions)[1]}')\n",
    "print(f'eXtreme Gradient Boost Tuned Accuracy: {score_retriever(y_test, xgb_best_parameters_predictions)[2]}')\n",
    "print(f'eXtreme Gradient Boost Tuned F1: {score_retriever(y_test, xgb_best_parameters_predictions)[3]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm_scores = algorithm_scores.append({'Model': 'XGBoost Tuned',\n",
    "                                            'Precision': score_retriever(y_test, xgb_best_parameters_predictions)[0],\n",
    "                                            'Recall': score_retriever(y_test, xgb_best_parameters_predictions)[1],\n",
    "                                            'Accuracy': score_retriever(y_test, xgb_best_parameters_predictions)[2],\n",
    "                                            'F1_Score': score_retriever(y_test, xgb_best_parameters_predictions)[3]},\n",
    "                                                        ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree Baseline</td>\n",
       "      <td>70.880253</td>\n",
       "      <td>54.292767</td>\n",
       "      <td>54.292767</td>\n",
       "      <td>60.699007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree Tuned</td>\n",
       "      <td>70.878984</td>\n",
       "      <td>54.272039</td>\n",
       "      <td>54.272039</td>\n",
       "      <td>60.680947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest Baseline</td>\n",
       "      <td>70.941492</td>\n",
       "      <td>54.699808</td>\n",
       "      <td>54.699808</td>\n",
       "      <td>61.007144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest Tuned</td>\n",
       "      <td>71.340484</td>\n",
       "      <td>54.125052</td>\n",
       "      <td>54.125052</td>\n",
       "      <td>60.674761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost Baseline</td>\n",
       "      <td>71.808436</td>\n",
       "      <td>61.875777</td>\n",
       "      <td>61.875777</td>\n",
       "      <td>66.041309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoost Tuned</td>\n",
       "      <td>72.113548</td>\n",
       "      <td>62.194249</td>\n",
       "      <td>62.194249</td>\n",
       "      <td>66.361805</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  Precision     Recall   Accuracy   F1_Score\n",
       "0  Decision Tree Baseline  70.880253  54.292767  54.292767  60.699007\n",
       "1     Decision Tree Tuned  70.878984  54.272039  54.272039  60.680947\n",
       "2  Random Forest Baseline  70.941492  54.699808  54.699808  61.007144\n",
       "3     Random Forest Tuned  71.340484  54.125052  54.125052  60.674761\n",
       "4        XGBoost Baseline  71.808436  61.875777  61.875777  66.041309\n",
       "5           XGBoost Tuned  72.113548  62.194249  62.194249  66.361805"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algorithm_scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
