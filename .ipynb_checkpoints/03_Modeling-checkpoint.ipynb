{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (accuracy_score, classification_report, f1_score, \n",
    "                             precision_score, recall_score)\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import data split and preprocessed in attached notebooks\n",
    "X_train = pd.read_csv('data/X_train.csv')\n",
    "y_train = pd.read_csv('data/y_train.csv')\n",
    "X_test = pd.read_csv('data/X_test.csv')\n",
    "y_test = pd.read_csv('data/y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = SMOTE().fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_retreiver(true_results, predictions):\n",
    "    precision = precision_score(true_results, predictions, average='weighted') * 100\n",
    "    recall = recall_score(true_results, predictions, average='weighted') * 100\n",
    "    accuracy = accuracy_score(true_results, predictions) * 100\n",
    "    f1 = f1_score(true_results, predictions, average='weighted') * 100\n",
    "    return precision, recall, accuracy, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm_scores = pd.DataFrame(columns=['Model', 'Precision', 'Recall', 'Accuracy', 'F1_Score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47212554417731323"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_classifier_default_params = DecisionTreeClassifier(random_state=42)\n",
    "dt_classifier_baseline_score = np.mean(cross_val_score(dt_classifier_default_params,\n",
    "                                                       X_train, y_train.values.ravel(), cv=5))\n",
    "dt_classifier_baseline_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Scores\n",
      "Decision Tree Baseline Precision: 71.33890215543977\n",
      "Decision Tree Baseline Recall: 58.286798283908816\n",
      "Decision Tree Baseline Accuracy: 58.286798283908816\n",
      "Decision Tree Baseline F1: 63.56492187427085\n"
     ]
    }
   ],
   "source": [
    "dt_classifier_default_params.fit(X_train, y_train.values.ravel())\n",
    "dt_classifier_baseline_predictions = dt_classifier_default_params.predict(X_test)\n",
    "print('Test Scores')\n",
    "print(f'Decision Tree Baseline Precision: {score_retreiver(y_test, dt_classifier_baseline_predictions)[0]}')\n",
    "print(f'Decision Tree Baseline Recall: {score_retreiver(y_test, dt_classifier_baseline_predictions)[1]}')\n",
    "print(f'Decision Tree Baseline Accuracy: {score_retreiver(y_test, dt_classifier_baseline_predictions)[2]}')\n",
    "print(f'Decision Tree Baseline F1: {score_retreiver(y_test, dt_classifier_baseline_predictions)[3]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm_scores = algorithm_scores.append({'Model': 'Decision Tree Baseline',\n",
    "                                            'Precision': score_retreiver(y_test, dt_classifier_baseline_predictions)[0],\n",
    "                                            'Recall': score_retreiver(y_test, dt_classifier_baseline_predictions)[1],\n",
    "                                            'Accuracy': score_retreiver(y_test, dt_classifier_baseline_predictions)[2],\n",
    "                                            'F1_Score': score_retreiver(y_test, dt_classifier_baseline_predictions)[3]},\n",
    "                                                        ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.07      0.36      0.12      6791\n",
      "           1       0.21      0.21      0.21     23863\n",
      "           2       0.84      0.66      0.74    128545\n",
      "\n",
      "    accuracy                           0.58    159199\n",
      "   macro avg       0.37      0.41      0.36    159199\n",
      "weighted avg       0.71      0.58      0.64    159199\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, dt_classifier_baseline_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = dt_classifier_default_params.cost_complexity_pruning_path(X_train, y_train)\n",
    "## Gather all alphas except for the last one which would return only the root node\n",
    "ccp_alphas = path.ccp_alphas[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None, 2, 5, 10, 15, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 5, 10],\n",
    "    'ccp_alpha': np.sort(ccp_alphas)[list(range(0, len(ccp_alphas), 500))]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_grid_search = GridSearchCV(DecisionTreeClassifier(random_state=42), dt_param_grid, cv=5)\n",
    "dt_grid_search = dt_grid_search.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_classifier_best_params = DecisionTreeClassifier(ccp_alpha=dt_grid_search.best_params_['ccp_alpha'],\n",
    "                                                   criterion=dt_grid_search.best_params_['criterion'],\n",
    "                                                   max_depth=dt_grid_search.best_params_['max_depth'],\n",
    "                                                   min_samples_leaf=dt_grid_search.best_params_['min_samples_leaf'],\n",
    "                                                   min_samples_split=dt_grid_search.best_params_['min_samples_split'],\n",
    "                                                   random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_classifier_best_params.fit(X_train, y_train)\n",
    "dt_best_parameters_predictions = dt_classifier_best_params.predict(X_test)\n",
    "print('Test Scores')\n",
    "print(f'Decision Tree Tuned Precision: {score_retreiver(y_test, dt_best_parameters_predictions)[0]}')\n",
    "print(f'Decision Tree Tuned Recall: {score_retreiver(y_test, dt_best_parameters_predictions)[1]}')\n",
    "print(f'Decision Tree Tuned Accuracy: {score_retreiver(y_test, dt_best_parameters_predictions)[2]}')\n",
    "print(f'Decision Tree Tuned F1: {score_retreiver(y_test, dt_best_parameters_predictions)[3]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm_scores = algorithm_scores.append({'Model': 'Decision Tree Tuned',\n",
    "                                            'Precision': score_retreiver(y_test, dt_best_parameters_predictions)[0],\n",
    "                                            'Recall': score_retreiver(y_test, dt_best_parameters_predictions)[1],\n",
    "                                            'Accuracy': score_retreiver(y_test, dt_best_parameters_predictions)[2],\n",
    "                                            'F1_Score': score_retreiver(y_test, dt_best_parameters_predictions)[3]},\n",
    "                                                        ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, dt_best_parameters_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier_default_params = RandomForestClassifier(random_state=42)\n",
    "rf_classifier_baseline_score = np.mean(cross_val_score(rf_classifier_default_params,\n",
    "                                                       X_train, y_train.values.ravel(), cv=5))\n",
    "rf_classifier_baseline_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier_default_params.fit(X_train, y_train.values.ravel())\n",
    "rf_classifier_baseline_predictions = rf_classifier_default_params.predict(X_test)\n",
    "print('Test Scores')\n",
    "print(f'Random Forest Baseline Precision: {score_retreiver(y_test, rf_classifier_baseline_predictions)[0]}')\n",
    "print(f'Random Forest Baseline Recall: {score_retreiver(y_test, rf_classifier_baseline_predictions)[1]}')\n",
    "print(f'Random Forest Baseline Accuracy: {score_retreiver(y_test, rf_classifier_baseline_predictions)[2]}')\n",
    "print(f'Random Forest Baseline F1: {score_retreiver(y_test, rf_classifier_baseline_predictions)[3]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm_scores = algorithm_scores.append({'Model': 'Random Forest Baseline',\n",
    "                                            'Precision': score_retreiver(y_test, rf_classifier_baseline_predictions)[0],\n",
    "                                            'Recall': score_retreiver(y_test, rf_classifier_baseline_predictions)[1],\n",
    "                                            'Accuracy': score_retreiver(y_test, rf_classifier_baseline_predictions)[2],\n",
    "                                            'F1_Score': score_retreiver(y_test, rf_classifier_baseline_predictions)[3]},\n",
    "                                                        ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, rf_classifier_baseline_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_param_grid = {\n",
    "    'criterion': ['entropy', 'gini'],\n",
    "    'max_depth': [None, 2, 5, 10, 15, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 5, 10],\n",
    "    'n_estimators': [10, 20, 50, 100]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_grid_search = GridSearchCV(RandomForestClassifier(random_state=42), rf_param_grid, cv=5)\n",
    "rf_grid_search = rf_grid_search.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier_best_params = RandomForestClassifier(criterion=rf_grid_search.best_params_['criterion'],\n",
    "                                                   max_depth=rf_grid_search.best_params_['max_depth'],\n",
    "                                                   min_samples_leaf=rf_grid_search.best_params_['min_samples_leaf'],\n",
    "                                                   min_samples_split=rf_grid_search.best_params_['min_samples_split'],\n",
    "                                                   n_estimators=rf_grid_search.best_params_['n_estimators'],\n",
    "                                                   random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier_best_params.fit(X_train, y_train)\n",
    "rf_best_parameters_predictions = rf_classifier_best_params.predict(X_test)\n",
    "print('Test Scores')\n",
    "print(f'Random Forest Tuned Precision: {score_retreiver(y_test, rf_best_parameters_predictions)[0]}')\n",
    "print(f'Random Forest Tuned Recall: {score_retreiver(y_test, rf_best_parameters_predictions)[1]}')\n",
    "print(f'Random Forest Tuned Accuracy: {score_retreiver(y_test, rf_best_parameters_predictions)[2]}')\n",
    "print(f'Random Forest Tuned F1: {score_retreiver(y_test, rf_best_parameters_predictions)[3]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm_scores = algorithm_scores.append({'Model': 'Random Forest Tuned',\n",
    "                                            'Precision': score_retreiver(y_test, rf_best_parameters_predictions)[0],\n",
    "                                            'Recall': score_retreiver(y_test, rf_best_parameters_predictions)[1],\n",
    "                                            'Accuracy': score_retreiver(y_test, rf_best_parameters_predictions)[2],\n",
    "                                            'F1_Score': score_retreiver(y_test, rf_best_parameters_predictions)[3]},\n",
    "                                                        ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, rf_best_parameters_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_feature_importance_dict = dict(zip(X_train.columns, rf_classifier_best_params.feature_importances_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummied_categories = ['steward', 'guards']\n",
    "for name in dummied_categories:\n",
    "    category_sum = sum([value for key, value in rf_feature_importance_dict.items() if name in key])\n",
    "    remove_keys = [key for key in rf_feature_importance_dict.keys() if name in key]\n",
    "    for key in remove_keys:\n",
    "        rf_feature_importance_dict.pop(key)\n",
    "    rf_feature_importance_dict[name] = category_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = pd.Series(rf_feature_importance_dict.values(), \n",
    "                        index=rf_feature_importance_dict.keys()).sort_values(ascending=False)\n",
    "sns.barplot(x=importances, y=importances.index);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### eXtreme Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_classifier_default_params = XGBClassifier(random_state=42, use_label_encoder=False)\n",
    "xgb_classifier_baseline_score = np.mean(cross_val_score(xgb_classifier_default_params,\n",
    "                                                        X_train, y_train.values.ravel(), cv=5))\n",
    "xgb_classifier_baseline_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_classifier_default_params.fit(X_train, y_train.values.ravel())\n",
    "xgb_classifier_baseline_predictions = xgb_classifier_default_params.predict(X_test)\n",
    "print('Test Scores')\n",
    "print(f'eXtreme Gradient Boost Baseline Precision: {score_retreiver(y_test, xgb_classifier_baseline_predictions)[0]}')\n",
    "print(f'eXtreme Gradient Boost Baseline Recall: {score_retreiver(y_test, xgb_classifier_baseline_predictions)[1]}')\n",
    "print(f'eXtreme Gradient Boost Baseline Accuracy: {score_retreiver(y_test, xgb_classifier_baseline_predictions)[2]}')\n",
    "print(f'eXtreme Gradient Boost Baseline F1: {score_retreiver(y_test, xgb_classifier_baseline_predictions)[3]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm_scores = algorithm_scores.append({'Model': 'XGBoost Baseline',\n",
    "                                            'Precision': score_retreiver(y_test, xgb_classifier_baseline_predictions)[0],\n",
    "                                            'Recall': score_retreiver(y_test, xgb_classifier_baseline_predictions)[1],\n",
    "                                            'Accuracy': score_retreiver(y_test, xgb_classifier_baseline_predictions)[2],\n",
    "                                            'F1_Score': score_retreiver(y_test, xgb_classifier_baseline_predictions)[3]},\n",
    "                                                        ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, xgb_classifier_baseline_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_param_grid = {\n",
    "    'learning_rate': [0.1, 0.2],\n",
    "    'max_depth': [6],\n",
    "    'min_child_weight': [1, 2],\n",
    "    'subsample': [0.5, 0.7],\n",
    "    'n_estimators': [100],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_grid_search = GridSearchCV(XGBClassifier(random_state=42, use_label_encoder=False),\n",
    "                               xgb_param_grid, scoring='accuracy', cv=5)\n",
    "xgb_grid_search = xgb_grid_search.fit(X_train, y_train.values.ravel())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
